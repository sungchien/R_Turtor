<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 利用R語言進行監督式機器學習 | R語言課程講義</title>
  <meta name="description" content="本課程介紹R語言的基本語法以及一些簡單的應用。" />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 利用R語言進行監督式機器學習 | R語言課程講義" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="本課程介紹R語言的基本語法以及一些簡單的應用。" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 利用R語言進行監督式機器學習 | R語言課程講義" />
  
  <meta name="twitter:description" content="本課程介紹R語言的基本語法以及一些簡單的應用。" />
  

<meta name="author" content="林頌堅" />


<meta name="date" content="2019-11-28" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="unsupervised-machine-learning.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R語言課程講義</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>前言</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> R語言的基本概念與語法</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#e8aab2e7a88be7b0a1e4bb8b"><i class="fa fa-check"></i>課程簡介</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#-1"><i class="fa fa-check"></i>課程簡介</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#e5adb8e7bf92e79baee6a899"><i class="fa fa-check"></i>學習目標</a></li>
</ul></li>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#r"><i class="fa fa-check"></i><b>1.1</b> R語言的基本概念</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#r"><i class="fa fa-check"></i><b>1.2</b> R語言的運算</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#r"><i class="fa fa-check"></i><b>1.3</b> R語言的基本資料型態</a><ul>
<li class="chapter" data-level="1.3.1" data-path="intro.html"><a href="intro.html#section-1.3.1"><i class="fa fa-check"></i><b>1.3.1</b> 數值資料型態</a></li>
<li class="chapter" data-level="1.3.2" data-path="intro.html"><a href="intro.html#section-1.3.2"><i class="fa fa-check"></i><b>1.3.2</b> 文字資料型態</a></li>
<li class="chapter" data-level="1.3.3" data-path="intro.html"><a href="intro.html#section-1.3.3"><i class="fa fa-check"></i><b>1.3.3</b> 邏輯資料型態</a></li>
<li class="chapter" data-level="1.3.4" data-path="intro.html"><a href="intro.html#factor"><i class="fa fa-check"></i><b>1.3.4</b> factor資料型態</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#r"><i class="fa fa-check"></i><b>1.4</b> R語言的特殊資料型態</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#vector"><i class="fa fa-check"></i><b>1.4.1</b> vector</a></li>
<li class="chapter" data-level="1.4.2" data-path="intro.html"><a href="intro.html#matrix"><i class="fa fa-check"></i><b>1.4.2</b> matrix</a></li>
<li class="chapter" data-level="1.4.3" data-path="intro.html"><a href="intro.html#list"><i class="fa fa-check"></i><b>1.4.3</b> list</a></li>
<li class="chapter" data-level="1.4.4" data-path="intro.html"><a href="intro.html#data-frame"><i class="fa fa-check"></i><b>1.4.4</b> data frame</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#e5b08fe7b590"><i class="fa fa-check"></i>小結</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#e5bbb6e4bcb8e6809de88083"><i class="fa fa-check"></i>延伸思考</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-manipulation.html"><a href="data-manipulation.html"><i class="fa fa-check"></i><b>2</b> 運用R語言進行資料處理</a><ul>
<li class="chapter" data-level="" data-path="data-manipulation.html"><a href="data-manipulation.html#-2"><i class="fa fa-check"></i>課程簡介</a><ul>
<li class="chapter" data-level="" data-path="data-manipulation.html"><a href="data-manipulation.html#-3"><i class="fa fa-check"></i>課程簡介</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#-1"><i class="fa fa-check"></i>學習目標</a></li>
</ul></li>
<li class="chapter" data-level="2.1" data-path="data-manipulation.html"><a href="data-manipulation.html#section-2.1"><i class="fa fa-check"></i><b>2.1</b> 預備工作</a><ul>
<li class="chapter" data-level="2.1.1" data-path="data-manipulation.html"><a href="data-manipulation.html#section-2.1.1"><i class="fa fa-check"></i><b>2.1.1</b> 設定工作目錄</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="data-manipulation.html"><a href="data-manipulation.html#section-2.2"><i class="fa fa-check"></i><b>2.2</b> 讀入檔案資料</a><ul>
<li class="chapter" data-level="2.2.1" data-path="data-manipulation.html"><a href="data-manipulation.html#section-2.2.1"><i class="fa fa-check"></i><b>2.2.1</b> 讀入空氣品質指標資料</a></li>
<li class="chapter" data-level="2.2.2" data-path="data-manipulation.html"><a href="data-manipulation.html#section-2.2.2"><i class="fa fa-check"></i><b>2.2.2</b> 瀏覽讀入的資料</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="data-manipulation.html"><a href="data-manipulation.html#section-2.3"><i class="fa fa-check"></i><b>2.3</b> 資料整理</a><ul>
<li class="chapter" data-level="2.3.1" data-path="data-manipulation.html"><a href="data-manipulation.html#aqina"><i class="fa fa-check"></i><b>2.3.1</b> 去除AQI為NA的資料紀錄</a></li>
<li class="chapter" data-level="2.3.2" data-path="data-manipulation.html"><a href="data-manipulation.html#variable"><i class="fa fa-check"></i><b>2.3.2</b> Variable資料型態變更</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="data-manipulation.html"><a href="data-manipulation.html#section-2.4"><i class="fa fa-check"></i><b>2.4</b> 資料分析</a><ul>
<li class="chapter" data-level="2.4.1" data-path="data-manipulation.html"><a href="data-manipulation.html#section-2.4.1"><i class="fa fa-check"></i><b>2.4.1</b> 找出某一縣市的偵測站</a></li>
<li class="chapter" data-level="2.4.2" data-path="data-manipulation.html"><a href="data-manipulation.html#section-2.4.2"><i class="fa fa-check"></i><b>2.4.2</b> 找出空氣品質最糟糕的偵測站</a></li>
<li class="chapter" data-level="2.4.3" data-path="data-manipulation.html"><a href="data-manipulation.html#section-2.4.3"><i class="fa fa-check"></i><b>2.4.3</b> 找出汙染物是細懸浮微粒的偵測站數量</a></li>
<li class="chapter" data-level="2.4.4" data-path="data-manipulation.html"><a href="data-manipulation.html#section-2.4.4"><i class="fa fa-check"></i><b>2.4.4</b> 計算各種空氣品質狀態的偵測站數量</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="data-manipulation.html"><a href="data-manipulation.html#section-2.5"><i class="fa fa-check"></i><b>2.5</b> 程式存檔</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#-1"><i class="fa fa-check"></i>小結</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#-1"><i class="fa fa-check"></i>延伸思考</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="tidyverse.html"><a href="tidyverse.html"><i class="fa fa-check"></i><b>3</b> Tidyverse簡介</a><ul>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#-4"><i class="fa fa-check"></i>課程簡介</a><ul>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#-5"><i class="fa fa-check"></i>課程簡介</a></li>
<li class="chapter" data-level="" data-path="data-manipulation.html"><a href="data-manipulation.html#-2"><i class="fa fa-check"></i>學習目標</a></li>
</ul></li>
<li class="chapter" data-level="3.1" data-path="tidyverse.html"><a href="tidyverse.html#tidy"><i class="fa fa-check"></i><b>3.1</b> tidy資料格式簡介</a><ul>
<li class="chapter" data-level="3.1.1" data-path="tidyverse.html"><a href="tidyverse.html#tidy"><i class="fa fa-check"></i><b>3.1.1</b> tidy資料格式的特徵</a></li>
<li class="chapter" data-level="3.1.2" data-path="tidyverse.html"><a href="tidyverse.html#tidy"><i class="fa fa-check"></i><b>3.1.2</b> tidy資料格式的優點</a></li>
<li class="chapter" data-level="3.1.3" data-path="tidyverse.html"><a href="tidyverse.html#wide-format-vs.long-format"><i class="fa fa-check"></i><b>3.1.3</b> wide format vs. long format</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="tidyverse.html"><a href="tidyverse.html#tidyverse"><i class="fa fa-check"></i><b>3.2</b> tidyverse套件</a></li>
<li class="chapter" data-level="3.3" data-path="tidyverse.html"><a href="tidyverse.html#tidy-data-format"><i class="fa fa-check"></i><b>3.3</b> tidy data format的資料分析方法</a><ul>
<li class="chapter" data-level="3.3.1" data-path="intro.html"><a href="intro.html#-1"><i class="fa fa-check"></i><b>3.3.1</b> 預備工作</a></li>
<li class="chapter" data-level="3.3.2" data-path="tidyverse.html"><a href="tidyverse.html#tidyverse"><i class="fa fa-check"></i><b>3.3.2</b> 使用tidyverse套件的函數</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="intro.html"><a href="intro.html#-1"><i class="fa fa-check"></i><b>3.4</b> 資料整理</a></li>
<li class="chapter" data-level="3.5" data-path="intro.html"><a href="intro.html#-1"><i class="fa fa-check"></i><b>3.5</b> 資料分析</a><ul>
<li class="chapter" data-level="3.5.1" data-path="intro.html"><a href="intro.html#-1"><i class="fa fa-check"></i><b>3.5.1</b> 找出某一縣市的偵測站</a></li>
<li class="chapter" data-level="3.5.2" data-path="intro.html"><a href="intro.html#-1"><i class="fa fa-check"></i><b>3.5.2</b> 找出空氣品質最糟糕的偵測站</a></li>
<li class="chapter" data-level="3.5.3" data-path="intro.html"><a href="intro.html#-1"><i class="fa fa-check"></i><b>3.5.3</b> 找出汙染物是細懸浮微粒的偵測站數量</a></li>
<li class="chapter" data-level="3.5.4" data-path="intro.html"><a href="intro.html#-1"><i class="fa fa-check"></i><b>3.5.4</b> 計算各種空氣品質狀態的偵測站數量</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data-manipulation.html"><a href="data-manipulation.html#-2"><i class="fa fa-check"></i>小結</a></li>
<li class="chapter" data-level="" data-path="data-manipulation.html"><a href="data-manipulation.html#-2"><i class="fa fa-check"></i>延伸思考</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-visualization.html"><a href="data-visualization.html"><i class="fa fa-check"></i><b>4</b> 資料視覺化</a><ul>
<li class="chapter" data-level="" data-path="data-visualization.html"><a href="data-visualization.html#-6"><i class="fa fa-check"></i>課程簡介</a><ul>
<li class="chapter" data-level="" data-path="data-visualization.html"><a href="data-visualization.html#-7"><i class="fa fa-check"></i>課程簡介</a></li>
<li class="chapter" data-level="" data-path="data-manipulation.html"><a href="data-manipulation.html#-3"><i class="fa fa-check"></i>學習目標</a></li>
</ul></li>
<li class="chapter" data-level="4.1" data-path="data-visualization.html"><a href="data-visualization.html#section-4.1"><i class="fa fa-check"></i><b>4.1</b> 資訊視覺化簡介</a><ul>
<li class="chapter" data-level="4.1.1" data-path="data-visualization.html"><a href="data-visualization.html#section-4.1.1"><i class="fa fa-check"></i><b>4.1.1</b> 視覺化的應用</a></li>
<li class="chapter" data-level="4.1.2" data-path="data-visualization.html"><a href="data-visualization.html#section-4.1.2"><i class="fa fa-check"></i><b>4.1.2</b> 應用圖形呈現各種問題</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="intro.html"><a href="intro.html#r"><i class="fa fa-check"></i><b>4.2</b> R語言的資料視覺化工具</a><ul>
<li class="chapter" data-level="4.2.1" data-path="data-visualization.html"><a href="data-visualization.html#ggplot2"><i class="fa fa-check"></i><b>4.2.1</b> ggplot2的運作概念</a></li>
<li class="chapter" data-level="4.2.2" data-path="data-visualization.html"><a href="data-visualization.html#aesthetics"><i class="fa fa-check"></i><b>4.2.2</b> Aesthetics上幾種常用的資料編碼方式</a></li>
<li class="chapter" data-level="4.2.3" data-path="data-visualization.html"><a href="data-visualization.html#ggplot2-geometrics"><i class="fa fa-check"></i><b>4.2.3</b> ggplot2上幾種常用的圖表類型 (Geometrics)</a></li>
<li class="chapter" data-level="4.2.4" data-path="data-visualization.html"><a href="data-visualization.html#ggplot2"><i class="fa fa-check"></i><b>4.2.4</b> 使用ggplot2套件</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="data-visualization.html"><a href="data-visualization.html#section-4.3"><i class="fa fa-check"></i><b>4.3</b> 以資料視覺化的方式進行資料探索</a><ul>
<li class="chapter" data-level="4.3.1" data-path="data-manipulation.html"><a href="data-manipulation.html#-2"><i class="fa fa-check"></i><b>4.3.1</b> 預備工作</a></li>
<li class="chapter" data-level="4.3.2" data-path="data-visualization.html"><a href="data-visualization.html#section-4.3.2"><i class="fa fa-check"></i><b>4.3.2</b> 問題</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="data-visualization.html"><a href="data-visualization.html#section-4.4"><i class="fa fa-check"></i><b>4.4</b> 利用直方圖呈現資料的分布情形</a></li>
<li class="chapter" data-level="4.5" data-path="data-visualization.html"><a href="data-visualization.html#section-4.5"><i class="fa fa-check"></i><b>4.5</b> 利用長條圖進行資料之間的比較</a></li>
<li class="chapter" data-level="4.6" data-path="data-visualization.html"><a href="data-visualization.html#section-4.6"><i class="fa fa-check"></i><b>4.6</b> 利用散佈圖呈現兩個數值之間的關係</a></li>
<li class="chapter" data-level="4.7" data-path="data-visualization.html"><a href="data-visualization.html#section-4.7"><i class="fa fa-check"></i><b>4.7</b> 使用盒狀圖比較多個群體的分布情形</a></li>
<li class="chapter" data-level="4.8" data-path="data-visualization.html"><a href="data-visualization.html#section-4.8"><i class="fa fa-check"></i><b>4.8</b> 利用並列的多個圖表進行比較</a></li>
<li class="chapter" data-level="" data-path="data-manipulation.html"><a href="data-manipulation.html#-3"><i class="fa fa-check"></i>小結</a></li>
<li class="chapter" data-level="" data-path="data-manipulation.html"><a href="data-manipulation.html#-3"><i class="fa fa-check"></i>延伸思考</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i><b>5</b> 利用R語言進行探索性資料分析</a><ul>
<li class="chapter" data-level="" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#-8"><i class="fa fa-check"></i>課程簡介</a><ul>
<li class="chapter" data-level="" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#-9"><i class="fa fa-check"></i>課程簡介</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#-4"><i class="fa fa-check"></i>學習目標</a></li>
</ul></li>
<li class="chapter" data-level="5.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#section-5.1"><i class="fa fa-check"></i><b>5.1</b> 探索性資料分析是什麼？</a></li>
<li class="chapter" data-level="5.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#section-5.2"><i class="fa fa-check"></i><b>5.2</b> 以環保署日空氣品質指標開放資料為例進行探索性資料分析</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#-4"><i class="fa fa-check"></i>小結</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#-4"><i class="fa fa-check"></i>延伸思考</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data-mining.html"><a href="data-mining.html"><i class="fa fa-check"></i><b>6</b> 資料探勘</a><ul>
<li class="chapter" data-level="" data-path="data-mining.html"><a href="data-mining.html#-10"><i class="fa fa-check"></i>課程簡介</a><ul>
<li class="chapter" data-level="" data-path="data-mining.html"><a href="data-mining.html#-11"><i class="fa fa-check"></i>課程簡介</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#-5"><i class="fa fa-check"></i>學習目標</a></li>
</ul></li>
<li class="chapter" data-level="6.1" data-path="data-mining.html"><a href="data-mining.html#section-6.1"><i class="fa fa-check"></i><b>6.1</b> 資料探勘的定義</a></li>
<li class="chapter" data-level="6.2" data-path="data-mining.html"><a href="data-mining.html#section-6.2"><i class="fa fa-check"></i><b>6.2</b> 資料探勘的步驟</a></li>
<li class="chapter" data-level="6.3" data-path="data-mining.html"><a href="data-mining.html#section-6.3"><i class="fa fa-check"></i><b>6.3</b> 資料探勘的分類</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="unsupervised-machine-learning.html"><a href="unsupervised-machine-learning.html"><i class="fa fa-check"></i><b>7</b> 利用R語言進行非監督式機器學習</a><ul>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning.html"><a href="unsupervised-machine-learning.html#-12"><i class="fa fa-check"></i>課程簡介</a><ul>
<li class="chapter" data-level="" data-path="unsupervised-machine-learning.html"><a href="unsupervised-machine-learning.html#-13"><i class="fa fa-check"></i>課程簡介</a></li>
<li class="chapter" data-level="" data-path="data-visualization.html"><a href="data-visualization.html#-6"><i class="fa fa-check"></i>學習目標</a></li>
</ul></li>
<li class="chapter" data-level="7.1" data-path="unsupervised-machine-learning.html"><a href="unsupervised-machine-learning.html#section-7.1"><i class="fa fa-check"></i><b>7.1</b> 集群分析</a></li>
<li class="chapter" data-level="7.2" data-path="unsupervised-machine-learning.html"><a href="unsupervised-machine-learning.html#section-7.2"><i class="fa fa-check"></i><b>7.2</b> 以進出站人數統計資料對臺鐵主要車站進行集群分析</a><ul>
<li class="chapter" data-level="7.2.1" data-path="unsupervised-machine-learning.html"><a href="unsupervised-machine-learning.html#section-7.2.1"><i class="fa fa-check"></i><b>7.2.1</b> 載入相關套件</a></li>
<li class="chapter" data-level="7.2.2" data-path="unsupervised-machine-learning.html"><a href="unsupervised-machine-learning.html#section-7.2.2"><i class="fa fa-check"></i><b>7.2.2</b> 選取資料</a></li>
<li class="chapter" data-level="7.2.3" data-path="unsupervised-machine-learning.html"><a href="unsupervised-machine-learning.html#section-7.2.3"><i class="fa fa-check"></i><b>7.2.3</b> 資料的清除與整理等前處理</a></li>
<li class="chapter" data-level="7.2.4" data-path="unsupervised-machine-learning.html"><a href="unsupervised-machine-learning.html#section-7.2.4"><i class="fa fa-check"></i><b>7.2.4</b> 產生站點資料特徵</a></li>
<li class="chapter" data-level="7.2.5" data-path="unsupervised-machine-learning.html"><a href="unsupervised-machine-learning.html#section-7.2.5"><i class="fa fa-check"></i><b>7.2.5</b> 維度縮減</a></li>
<li class="chapter" data-level="7.2.6" data-path="unsupervised-machine-learning.html"><a href="unsupervised-machine-learning.html#section-7.2.6"><i class="fa fa-check"></i><b>7.2.6</b> 將站點依據彼此距離視覺化</a></li>
<li class="chapter" data-level="7.2.7" data-path="unsupervised-machine-learning.html"><a href="unsupervised-machine-learning.html#section-7.2.7"><i class="fa fa-check"></i><b>7.2.7</b> 站點集群</a></li>
<li class="chapter" data-level="7.2.8" data-path="unsupervised-machine-learning.html"><a href="unsupervised-machine-learning.html#section-7.2.8"><i class="fa fa-check"></i><b>7.2.8</b> 結果的解釋</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#-5"><i class="fa fa-check"></i>小結</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#-5"><i class="fa fa-check"></i>延伸思考</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html"><i class="fa fa-check"></i><b>8</b> 利用R語言進行監督式機器學習</a><ul>
<li class="chapter" data-level="" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#-14"><i class="fa fa-check"></i>課程簡介</a><ul>
<li class="chapter" data-level="" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#-15"><i class="fa fa-check"></i>課程簡介</a></li>
<li class="chapter" data-level="" data-path="data-visualization.html"><a href="data-visualization.html#-7"><i class="fa fa-check"></i>學習目標</a></li>
</ul></li>
<li class="chapter" data-level="8.1" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#section-8.1"><i class="fa fa-check"></i><b>8.1</b> 監督式機器學習</a><ul>
<li class="chapter" data-level="8.1.1" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#section-8.1.1"><i class="fa fa-check"></i><b>8.1.1</b> 分類</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#tmdb"><i class="fa fa-check"></i><b>8.2</b> TMDB電影評分預測</a><ul>
<li class="chapter" data-level="8.2.1" data-path="tidyverse.html"><a href="tidyverse.html#tidyverse"><i class="fa fa-check"></i><b>8.2.1</b> 載入tidyverse套件</a></li>
<li class="chapter" data-level="8.2.2" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#section-8.2.2"><i class="fa fa-check"></i><b>8.2.2</b> 讀入資料</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#section-8.3"><i class="fa fa-check"></i><b>8.3</b> 資料處理與特徵抽取</a><ul>
<li class="chapter" data-level="8.3.1" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#section-8.3.1"><i class="fa fa-check"></i><b>8.3.1</b> 資料的清除與整理</a></li>
<li class="chapter" data-level="8.3.2" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#section-8.3.2"><i class="fa fa-check"></i><b>8.3.2</b> 轉換資料為有效描述和預測的特徵</a></li>
<li class="chapter" data-level="8.3.3" data-path="intro.html"><a href="intro.html#data-frame"><i class="fa fa-check"></i><b>8.3.3</b> 建立一個data frame用來比較各種分類演算法</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#k-nearest-neightbors"><i class="fa fa-check"></i><b>8.4</b> 進行K-Nearest Neightbors分類</a></li>
<li class="chapter" data-level="8.5" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#naive-bayes"><i class="fa fa-check"></i><b>8.5</b> 進行Naive Bayes演算法分類</a></li>
<li class="chapter" data-level="8.6" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#section-8.6"><i class="fa fa-check"></i><b>8.6</b> 進行支持向量機分類</a></li>
<li class="chapter" data-level="8.7" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#section-8.7"><i class="fa fa-check"></i><b>8.7</b> 進行決策樹分類</a></li>
<li class="chapter" data-level="8.8" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#section-8.8"><i class="fa fa-check"></i><b>8.8</b> 進行隨機森林分類</a></li>
<li class="chapter" data-level="8.9" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#section-8.9"><i class="fa fa-check"></i><b>8.9</b> 進行梯度提升機分類</a></li>
<li class="chapter" data-level="8.10" data-path="supervised-machine-learning.html"><a href="supervised-machine-learning.html#section-8.10"><i class="fa fa-check"></i><b>8.10</b> 比較各分類器的結果</a></li>
<li class="chapter" data-level="" data-path="data-visualization.html"><a href="data-visualization.html#-6"><i class="fa fa-check"></i>小結</a></li>
<li class="chapter" data-level="" data-path="data-visualization.html"><a href="data-visualization.html#-6"><i class="fa fa-check"></i>延伸思考</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R語言課程講義</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="supervised_machine_learning" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> 利用R語言進行監督式機器學習</h1>
<div id="-14" class="section level2 unnumbered">
<h2>課程簡介</h2>
<div id="-15" class="section level3 unnumbered">
<h3>課程簡介</h3>
<p><strong>分類</strong>是根據蒐集的資料案例，以訓練演算法建立一個模型，來指定新的資料的類別。本次課程的目的為介紹監督式機器學習中的分類問題，並且以實際案例說明分類問題的資料處理、特徵抽取與運用各種演算法進行分類。本次課程中將利用TMDB電影資料，從片長、類型、製作公司、預算、收入、…等電影資料，預測電影的評分，進行分類的練習。本次課程包含以下的內容：</p>
<ul>
<li>分類演算法的概念與應用</li>
<li>資料處理與特徵抽取</li>
<li>R語言的分類演算法實作</li>
</ul>
</div>
<div id="-7" class="section level3 unnumbered">
<h3>學習目標</h3>
</div>
</div>
<div id="section-8.1" class="section level2">
<h2><span class="header-section-number">8.1</span> 監督式機器學習</h2>
<p>監督式機器學習 (supervised machine learning)是利用一組已經標注結果的資料，預測尚未標注結果的新資料的可能結果。以數學的方式來表示這個概念，監督式機器學習利用一組資料 <span class="math inline">\(X_{1}, X_{2}, ..., X_{N}\)</span> (<span class="math inline">\(X_{i}\)</span>稱為預測變數或解釋變數)以及其對應的結果 <span class="math inline">\(Y_{1}, Y_{2}, ..., Y_{N}\)</span> (<span class="math inline">\(Y_{i}\)</span>稱為目標變數)，設法找到一個模型 <span class="math inline">\(f(x)\)</span> ，盡可能使 <span class="math inline">\(f(X_{1}) = Y_{1}\)</span> 、 <span class="math inline">\(f(X_{2}) = Y_{2}\)</span> 、…、 <span class="math inline">\(f(X_{N}) = Y_{N}\)</span> 。當有新的資料 <span class="math inline">\(\hat{X}\)</span> 進入時，可以利用 <span class="math inline">\(f(x)\)</span> 計算的結果 <span class="math inline">\(f(\hat{X})\)</span> ，做為可能結果的預測。</p>
<hr />
<p>通常來說，如果要預測的結果是連續的數值，通常將這類的問題稱為<strong>迴歸 (regression)</strong>，如果是離散型的結果的話，則稱為<strong>分類 (classification)</strong>。</p>
<div id="section-8.1.1" class="section level3">
<h3><span class="header-section-number">8.1.1</span> 分類</h3>
<p>分類的問題可以視為運用現有的資料 <span class="math inline">\(X_{1}, X_{2}, ..., X_{N}\)</span> 以及其對應的類別 <span class="math inline">\(Y_{1}, Y_{2}, ..., Y_{N}\)</span> ，嘗試找到一個分類器模型 <span class="math inline">\(f(x)\)</span> 來預測新資料 <span class="math inline">\(\hat{X}\)</span> 的類別 <span class="math inline">\(f(\hat{X})\)</span> 。</p>
<p>常用的分類演算法:</p>
<ul>
<li>K-Nearest Neighbors演算法</li>
<li>Naive Bayes 分類演算法</li>
<li>支援向量機 (support vector machine)</li>
<li>決策樹 (decision tree)</li>
<li>隨機森林 (random forest)</li>
<li>梯度提升機 (gradient boosting machine)</li>
</ul>
<p>這些分類演算法各有各的優點，有的容易實作，有的效率高，有的產生的結果容易解釋，有的則是整合其他分類演算法的結果。在應用上，可以依據分類問題的特性進行選擇。</p>
</div>
</div>
<div id="tmdb" class="section level2">
<h2><span class="header-section-number">8.2</span> TMDB電影評分預測</h2>
<p>TMDB資料是<a href="https://www.kaggle.com/">Kaggle</a>提供做為學習資料科學的資料集。Kaggle利用<a href="https://www.themoviedb.org/?language=zh-TW">TMDB (The Movie Database)</a>提供的電影資料建立的資料集，大約有5000筆電影資料，在Kaggle上的下載點為<a href="https://www.kaggle.com/tmdb/tmdb-movie-metadata/downloads/tmdb-5000-movie-dataset.zip/2">TMDB 5000 Movie Dataset</a>。</p>
<div class="figure">
<img src="image/tmdb.png" />

</div>
<p>本次課程將利用TMDB資料集說明如何應用電影資料(片長、類型、製作公司、預算、收入、…等)，進行監督式機器學習，預測電影評分。可參考<a href="http://rstudio-pubs-static.s3.amazonaws.com/342210_7c8d57cfdd784cf58dc077d3eb7a2ca3.html#problem-statement">Project Report: IMDB 5000 Movie Dataset</a>，有類似的做法。</p>
<div id="tidyverse" class="section level3">
<h3><span class="header-section-number">8.2.1</span> 載入tidyverse套件</h3>
<p>載入<code>tidyverse</code>套件</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)</code></pre></div>
</div>
<div id="section-8.2.2" class="section level3">
<h3><span class="header-section-number">8.2.2</span> 讀入資料</h3>
<p>讀取TMDB資料集</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;tmdb_5000_movies.csv&quot;</span>)</code></pre></div>
<div class="figure">
<img src="image/tmdb_data.png" />

</div>
<p>讀入資料集後，先看資料集的情況。</p>
<p>資料集上各個variable的資料型態</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(movies)</code></pre></div>
<pre><code>## Classes &#39;spec_tbl_df&#39;, &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 4803 obs. of  20 variables:
##  $ budget              : num  2.37e+08 3.00e+08 2.45e+08 2.50e+08 2.60e+08 2.58e+08 2.60e+08 2.80e+08 2.50e+08 2.50e+08 ...
##  $ genres              : chr  &quot;[{\&quot;id\&quot;: 28, \&quot;name\&quot;: \&quot;Action\&quot;}, {\&quot;id\&quot;: 12, \&quot;name\&quot;: \&quot;Adventure\&quot;}, {\&quot;id\&quot;: 14, \&quot;name\&quot;: \&quot;Fantasy\&quot;}&quot;| __truncated__ &quot;[{\&quot;id\&quot;: 12, \&quot;name\&quot;: \&quot;Adventure\&quot;}, {\&quot;id\&quot;: 14, \&quot;name\&quot;: \&quot;Fantasy\&quot;}, {\&quot;id\&quot;: 28, \&quot;name\&quot;: \&quot;Action\&quot;}]&quot; &quot;[{\&quot;id\&quot;: 28, \&quot;name\&quot;: \&quot;Action\&quot;}, {\&quot;id\&quot;: 12, \&quot;name\&quot;: \&quot;Adventure\&quot;}, {\&quot;id\&quot;: 80, \&quot;name\&quot;: \&quot;Crime\&quot;}]&quot; &quot;[{\&quot;id\&quot;: 28, \&quot;name\&quot;: \&quot;Action\&quot;}, {\&quot;id\&quot;: 80, \&quot;name\&quot;: \&quot;Crime\&quot;}, {\&quot;id\&quot;: 18, \&quot;name\&quot;: \&quot;Drama\&quot;}, {\&quot;i&quot;| __truncated__ ...
##  $ homepage            : chr  &quot;http://www.avatarmovie.com/&quot; &quot;http://disney.go.com/disneypictures/pirates/&quot; &quot;http://www.sonypictures.com/movies/spectre/&quot; &quot;http://www.thedarkknightrises.com/&quot; ...
##  $ id                  : num  19995 285 206647 49026 49529 ...
##  $ keywords            : chr  &quot;[{\&quot;id\&quot;: 1463, \&quot;name\&quot;: \&quot;culture clash\&quot;}, {\&quot;id\&quot;: 2964, \&quot;name\&quot;: \&quot;future\&quot;}, {\&quot;id\&quot;: 3386, \&quot;name\&quot;: \&quot;&quot;| __truncated__ &quot;[{\&quot;id\&quot;: 270, \&quot;name\&quot;: \&quot;ocean\&quot;}, {\&quot;id\&quot;: 726, \&quot;name\&quot;: \&quot;drug abuse\&quot;}, {\&quot;id\&quot;: 911, \&quot;name\&quot;: \&quot;exotic &quot;| __truncated__ &quot;[{\&quot;id\&quot;: 470, \&quot;name\&quot;: \&quot;spy\&quot;}, {\&quot;id\&quot;: 818, \&quot;name\&quot;: \&quot;based on novel\&quot;}, {\&quot;id\&quot;: 4289, \&quot;name\&quot;: \&quot;secr&quot;| __truncated__ &quot;[{\&quot;id\&quot;: 849, \&quot;name\&quot;: \&quot;dc comics\&quot;}, {\&quot;id\&quot;: 853, \&quot;name\&quot;: \&quot;crime fighter\&quot;}, {\&quot;id\&quot;: 949, \&quot;name\&quot;: \&quot;&quot;| __truncated__ ...
##  $ original_language   : chr  &quot;en&quot; &quot;en&quot; &quot;en&quot; &quot;en&quot; ...
##  $ original_title      : chr  &quot;Avatar&quot; &quot;Pirates of the Caribbean: At World&#39;s End&quot; &quot;Spectre&quot; &quot;The Dark Knight Rises&quot; ...
##  $ overview            : chr  &quot;In the 22nd century, a paraplegic Marine is dispatched to the moon Pandora on a unique mission, but becomes tor&quot;| __truncated__ &quot;Captain Barbossa, long believed to be dead, has come back to life and is headed to the edge of the Earth with W&quot;| __truncated__ &quot;A cryptic message from Bond’s past sends him on a trail to uncover a sinister organization. While M battles pol&quot;| __truncated__ &quot;Following the death of District Attorney Harvey Dent, Batman assumes responsibility for Dent&#39;s crimes to protec&quot;| __truncated__ ...
##  $ popularity          : num  150.4 139.1 107.4 112.3 43.9 ...
##  $ production_companies: chr  &quot;[{\&quot;name\&quot;: \&quot;Ingenious Film Partners\&quot;, \&quot;id\&quot;: 289}, {\&quot;name\&quot;: \&quot;Twentieth Century Fox Film Corporation\&quot;, \&quot;| __truncated__ &quot;[{\&quot;name\&quot;: \&quot;Walt Disney Pictures\&quot;, \&quot;id\&quot;: 2}, {\&quot;name\&quot;: \&quot;Jerry Bruckheimer Films\&quot;, \&quot;id\&quot;: 130}, {\&quot;name&quot;| __truncated__ &quot;[{\&quot;name\&quot;: \&quot;Columbia Pictures\&quot;, \&quot;id\&quot;: 5}, {\&quot;name\&quot;: \&quot;Danjaq\&quot;, \&quot;id\&quot;: 10761}, {\&quot;name\&quot;: \&quot;B24\&quot;, \&quot;id\&quot;: 69434}]&quot; &quot;[{\&quot;name\&quot;: \&quot;Legendary Pictures\&quot;, \&quot;id\&quot;: 923}, {\&quot;name\&quot;: \&quot;Warner Bros.\&quot;, \&quot;id\&quot;: 6194}, {\&quot;name\&quot;: \&quot;DC E&quot;| __truncated__ ...
##  $ production_countries: chr  &quot;[{\&quot;iso_3166_1\&quot;: \&quot;US\&quot;, \&quot;name\&quot;: \&quot;United States of America\&quot;}, {\&quot;iso_3166_1\&quot;: \&quot;GB\&quot;, \&quot;name\&quot;: \&quot;United Kingdom\&quot;}]&quot; &quot;[{\&quot;iso_3166_1\&quot;: \&quot;US\&quot;, \&quot;name\&quot;: \&quot;United States of America\&quot;}]&quot; &quot;[{\&quot;iso_3166_1\&quot;: \&quot;GB\&quot;, \&quot;name\&quot;: \&quot;United Kingdom\&quot;}, {\&quot;iso_3166_1\&quot;: \&quot;US\&quot;, \&quot;name\&quot;: \&quot;United States of America\&quot;}]&quot; &quot;[{\&quot;iso_3166_1\&quot;: \&quot;US\&quot;, \&quot;name\&quot;: \&quot;United States of America\&quot;}]&quot; ...
##  $ release_date        : Date, format: &quot;2009-12-10&quot; &quot;2007-05-19&quot; ...
##  $ revenue             : num  2.79e+09 9.61e+08 8.81e+08 1.08e+09 2.84e+08 ...
##  $ runtime             : num  162 169 148 165 132 139 100 141 153 151 ...
##  $ spoken_languages    : chr  &quot;[{\&quot;iso_639_1\&quot;: \&quot;en\&quot;, \&quot;name\&quot;: \&quot;English\&quot;}, {\&quot;iso_639_1\&quot;: \&quot;es\&quot;, \&quot;name\&quot;: \&quot;Espa\\u00f1ol\&quot;}]&quot; &quot;[{\&quot;iso_639_1\&quot;: \&quot;en\&quot;, \&quot;name\&quot;: \&quot;English\&quot;}]&quot; &quot;[{\&quot;iso_639_1\&quot;: \&quot;fr\&quot;, \&quot;name\&quot;: \&quot;Fran\\u00e7ais\&quot;}, {\&quot;iso_639_1\&quot;: \&quot;en\&quot;, \&quot;name\&quot;: \&quot;English\&quot;}, {\&quot;iso_&quot;| __truncated__ &quot;[{\&quot;iso_639_1\&quot;: \&quot;en\&quot;, \&quot;name\&quot;: \&quot;English\&quot;}]&quot; ...
##  $ status              : chr  &quot;Released&quot; &quot;Released&quot; &quot;Released&quot; &quot;Released&quot; ...
##  $ tagline             : chr  &quot;Enter the World of Pandora.&quot; &quot;At the end of the world, the adventure begins.&quot; &quot;A Plan No One Escapes&quot; &quot;The Legend Ends&quot; ...
##  $ title               : chr  &quot;Avatar&quot; &quot;Pirates of the Caribbean: At World&#39;s End&quot; &quot;Spectre&quot; &quot;The Dark Knight Rises&quot; ...
##  $ vote_average        : num  7.2 6.9 6.3 7.6 6.1 5.9 7.4 7.3 7.4 5.7 ...
##  $ vote_count          : num  11800 4500 4466 9106 2124 ...
##  - attr(*, &quot;spec&quot;)=
##   .. cols(
##   ..   budget = col_double(),
##   ..   genres = col_character(),
##   ..   homepage = col_character(),
##   ..   id = col_double(),
##   ..   keywords = col_character(),
##   ..   original_language = col_character(),
##   ..   original_title = col_character(),
##   ..   overview = col_character(),
##   ..   popularity = col_double(),
##   ..   production_companies = col_character(),
##   ..   production_countries = col_character(),
##   ..   release_date = col_date(format = &quot;&quot;),
##   ..   revenue = col_double(),
##   ..   runtime = col_double(),
##   ..   spoken_languages = col_character(),
##   ..   status = col_character(),
##   ..   tagline = col_character(),
##   ..   title = col_character(),
##   ..   vote_average = col_double(),
##   ..   vote_count = col_double()
##   .. )</code></pre>
<p>資料集上各個variable的統計描述資訊</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(movies)</code></pre></div>
<pre><code>##      budget             genres            homepage        
##  Min.   :        0   Length:4803        Length:4803       
##  1st Qu.:   790000   Class :character   Class :character  
##  Median : 15000000   Mode  :character   Mode  :character  
##  Mean   : 29045040                                        
##  3rd Qu.: 40000000                                        
##  Max.   :380000000                                        
##                                                           
##        id           keywords         original_language  original_title    
##  Min.   :     5   Length:4803        Length:4803        Length:4803       
##  1st Qu.:  9014   Class :character   Class :character   Class :character  
##  Median : 14629   Mode  :character   Mode  :character   Mode  :character  
##  Mean   : 57166                                                           
##  3rd Qu.: 58611                                                           
##  Max.   :459488                                                           
##                                                                           
##    overview           popularity      production_companies
##  Length:4803        Min.   :  0.000   Length:4803         
##  Class :character   1st Qu.:  4.668   Class :character    
##  Mode  :character   Median : 12.922   Mode  :character    
##                     Mean   : 21.492                       
##                     3rd Qu.: 28.314                       
##                     Max.   :875.581                       
##                                                           
##  production_countries  release_date           revenue         
##  Length:4803          Min.   :1916-09-04   Min.   :0.000e+00  
##  Class :character     1st Qu.:1999-07-14   1st Qu.:0.000e+00  
##  Mode  :character     Median :2005-10-03   Median :1.917e+07  
##                       Mean   :2002-12-27   Mean   :8.226e+07  
##                       3rd Qu.:2011-02-16   3rd Qu.:9.292e+07  
##                       Max.   :2017-02-03   Max.   :2.788e+09  
##                       NA&#39;s   :1                               
##     runtime      spoken_languages      status            tagline         
##  Min.   :  0.0   Length:4803        Length:4803        Length:4803       
##  1st Qu.: 94.0   Class :character   Class :character   Class :character  
##  Median :103.0   Mode  :character   Mode  :character   Mode  :character  
##  Mean   :106.9                                                           
##  3rd Qu.:118.0                                                           
##  Max.   :338.0                                                           
##  NA&#39;s   :2                                                               
##     title            vote_average      vote_count     
##  Length:4803        Min.   : 0.000   Min.   :    0.0  
##  Class :character   1st Qu.: 5.600   1st Qu.:   54.0  
##  Mode  :character   Median : 6.200   Median :  235.0  
##                     Mean   : 6.092   Mean   :  690.2  
##                     3rd Qu.: 6.800   3rd Qu.:  737.0  
##                     Max.   :10.000   Max.   :13752.0  
## </code></pre>
</div>
</div>
<div id="section-8.3" class="section level2">
<h2><span class="header-section-number">8.3</span> 資料處理與特徵抽取</h2>
<div id="section-8.3.1" class="section level3">
<h3><span class="header-section-number">8.3.1</span> 資料的清除與整理</h3>
<p>整理各個variable，分為以下四類</p>
<ol style="list-style-type: decimal">
<li>電影編號：id</li>
<li>與本次分析無關者：homepage, keywords, original_title, overview, production_countries, spoken_languages, status, tagline, title</li>
<li>數值資料類型：budget, popularity, revenue, runtime, vote_average, vote_count</li>
<li>日期資料類型：release_date</li>
<li>簡單字串資料類型：original_language</li>
<li>複雜字串資料類型：genres, production_companies</li>
</ol>
<hr />
<p><strong>處理與本次分析無關的variables</strong></p>
<p>與本次分析無關的variables，不需進一步分析，可以直接捨棄。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies &lt;-<span class="st"> </span>movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>homepage, <span class="op">-</span>keywords, <span class="op">-</span>original_title, <span class="op">-</span>overview, <span class="op">-</span>production_countries, <span class="op">-</span>spoken_languages, <span class="op">-</span>status, <span class="op">-</span>tagline, <span class="op">-</span>title)</code></pre></div>
<p>捨棄這些variables後，資料集從20個variables，轉換為11個variables。</p>
<hr />
<p><strong>整理數值資料類型的variables</strong></p>
<p>觀察每個數值資料的範圍</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(budget, popularity, revenue, runtime, vote_average, vote_count) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summary</span>()</code></pre></div>
<pre><code>##      budget            popularity         revenue             runtime     
##  Min.   :        0   Min.   :  0.000   Min.   :0.000e+00   Min.   :  0.0  
##  1st Qu.:   790000   1st Qu.:  4.668   1st Qu.:0.000e+00   1st Qu.: 94.0  
##  Median : 15000000   Median : 12.922   Median :1.917e+07   Median :103.0  
##  Mean   : 29045040   Mean   : 21.492   Mean   :8.226e+07   Mean   :106.9  
##  3rd Qu.: 40000000   3rd Qu.: 28.314   3rd Qu.:9.292e+07   3rd Qu.:118.0  
##  Max.   :380000000   Max.   :875.581   Max.   :2.788e+09   Max.   :338.0  
##                                                            NA&#39;s   :2      
##   vote_average      vote_count     
##  Min.   : 0.000   Min.   :    0.0  
##  1st Qu.: 5.600   1st Qu.:   54.0  
##  Median : 6.200   Median :  235.0  
##  Mean   : 6.092   Mean   :  690.2  
##  3rd Qu.: 6.800   3rd Qu.:  737.0  
##  Max.   :10.000   Max.   :13752.0  
## </code></pre>
<p><code>budget</code>(預算)、<code>revenue</code>(收入)、<code>runtime</code>(放映時間)、<code>vote_count</code>(投票人數)等為0並不合理，首先刪除這些資料為0者</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies &lt;-<span class="st"> </span>movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(budget<span class="op">&gt;</span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>revenue<span class="op">&gt;</span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>runtime<span class="op">&gt;</span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>vote_count<span class="op">&gt;</span><span class="dv">0</span>)</code></pre></div>
<p>再觀察每個數值資料的範圍</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(budget, popularity, revenue, runtime, vote_average, vote_count) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summary</span>()</code></pre></div>
<pre><code>##      budget            popularity        revenue             runtime     
##  Min.   :        1   Min.   :  0.02   Min.   :5.000e+00   Min.   : 41.0  
##  1st Qu.: 10500000   1st Qu.: 10.48   1st Qu.:1.704e+07   1st Qu.: 96.0  
##  Median : 25000000   Median : 20.42   Median :5.520e+07   Median :107.0  
##  Mean   : 40678774   Mean   : 29.05   Mean   :1.213e+08   Mean   :110.7  
##  3rd Qu.: 55000000   3rd Qu.: 37.35   3rd Qu.:1.464e+08   3rd Qu.:121.0  
##  Max.   :380000000   Max.   :875.58   Max.   :2.788e+09   Max.   :338.0  
##   vote_average     vote_count     
##  Min.   :2.300   Min.   :    1.0  
##  1st Qu.:5.800   1st Qu.:  178.0  
##  Median :6.300   Median :  471.0  
##  Mean   :6.313   Mean   :  977.9  
##  3rd Qu.:6.900   3rd Qu.: 1148.0  
##  Max.   :8.500   Max.   :13752.0</code></pre>
<hr />
<p><code>budget</code>最小為1 ，看起來仍然不合理。顯示<code>budget</code>少於10000的電影共幾筆？</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">paste</span>(<span class="st">&quot;budget少於10000的電影數量：&quot;</span>, <span class="kw">nrow</span>(movies[movies<span class="op">$</span>budget<span class="op">&lt;</span><span class="dv">10000</span>,])))</code></pre></div>
<pre><code>## [1] &quot;budget少於10000的電影數量： 15&quot;</code></pre>
<p>刪除<code>budget</code>少於10000的電影</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies &lt;-<span class="st"> </span>movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(budget<span class="op">&gt;=</span><span class="dv">10000</span>)</code></pre></div>
<hr />
<p>收入太少，也不正常，顯示<code>revenue</code>少於10000的電影共幾筆？</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">paste</span>(<span class="st">&quot;revenue少於10000的電影數量：&quot;</span>, <span class="kw">nrow</span>(movies[movies<span class="op">$</span>revenue<span class="op">&lt;</span><span class="dv">10000</span>,])))</code></pre></div>
<pre><code>## [1] &quot;revenue少於10000的電影數量： 8&quot;</code></pre>
<p>再刪除<code>revenue</code>少於10000的電影</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies &lt;-<span class="st"> </span>movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(revenue<span class="op">&gt;=</span><span class="dv">10000</span>)</code></pre></div>
<hr />
<p>分析<code>runtime</code>的分布情形</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(movies<span class="op">$</span>runtime)</code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    41.0    96.0   107.0   110.8   121.0   338.0</code></pre>
<p>畫成直方圖看看</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x=</span>runtime), <span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">360</span>, <span class="dv">30</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">360</span>, <span class="dv">30</span>), <span class="dt">minor_breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y=</span><span class="st">&quot;電影數量&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.background =</span> <span class="kw">element_blank</span>(),
        <span class="dt">axis.line =</span> <span class="kw">element_line</span>(<span class="dt">color=</span><span class="st">&quot;grey&quot;</span>),
        <span class="dt">panel.grid.major.y =</span> <span class="kw">element_line</span>(<span class="dt">color=</span><span class="st">&quot;grey90&quot;</span>))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>刪除runtime小於60分鐘的電影</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies &lt;-<span class="st"> </span>movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(runtime<span class="op">&gt;=</span><span class="dv">60</span>)</code></pre></div>
<hr />
<p>最後分析<code>vote_count</code>，由於我們希望預測電影的評分資料，如果評分人數太少，評分可能較不準確。顯示<code>vote_count</code>少於100的電影共幾筆？</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">paste</span>(<span class="st">&quot;vote_count少於100的電影數量：&quot;</span>, <span class="kw">nrow</span>(movies[movies<span class="op">$</span>vote_count<span class="op">&lt;</span><span class="dv">100</span>,])))</code></pre></div>
<pre><code>## [1] &quot;vote_count少於100的電影數量： 496&quot;</code></pre>
<p>再刪除<code>vote_count</code>少於100的電影</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies &lt;-<span class="st"> </span>movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(vote_count<span class="op">&gt;=</span><span class="dv">100</span>)</code></pre></div>
<hr />
<p>我們要預測的目標是平均評分<code>vote_average</code>，檢視這個variable的分布情形。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x=</span>vote_average), <span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="fl">0.5</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="fl">0.5</span>), <span class="dt">minor_breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;vote_average區間&quot;</span>, <span class="dt">y=</span><span class="st">&quot;電影數量&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.background =</span> <span class="kw">element_blank</span>(),
        <span class="dt">axis.line=</span><span class="kw">element_line</span>(<span class="dt">color=</span><span class="st">&quot;grey&quot;</span>),
        <span class="dt">panel.grid.major.y =</span> <span class="kw">element_line</span>(<span class="dt">color=</span><span class="st">&quot;grey90&quot;</span>),
        <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle=</span><span class="dv">60</span>, <span class="dt">hjust=</span><span class="dv">1</span>))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>從上面的圖形可以發現資料分布在2.5到8.5之間 根據<code>vote_average</code>的分布情形，決定將這個variable分為<span class="math inline">\(x\leq5.5\)</span>, <span class="math inline">\(5.5&lt;x\leq6.5\)</span>, <span class="math inline">\(6.5&lt;x\leq7.5\)</span>以及<span class="math inline">\(7.5&lt;x\)</span>等四個區間，將<code>vote_average</code>改為新的變數<code>vote_average_p</code>，做為接下來預測的目標。也就是以其他的variables來預測<code>vote_average_p</code>在哪一個區間(類別)。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies &lt;-<span class="st"> </span>movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">vote_average_p=</span><span class="kw">cut</span>(vote_average, <span class="dt">breaks=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">5.5</span>, <span class="fl">6.5</span>, <span class="fl">7.5</span>, <span class="dv">10</span>)))</code></pre></div>
<pre><code>## Warning: The `printer` argument is deprecated as of rlang 0.3.0.
## This warning is displayed once per session.</code></pre>
<p>檢視各類別內的資料數量</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(vote_average_p) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">count=</span><span class="kw">n</span>()) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ratio=</span>count<span class="op">/</span><span class="kw">sum</span>(count)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>(<span class="kw">aes</span>(<span class="dt">x=</span>vote_average_p, <span class="dt">y=</span>ratio)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;vote_average_p類別&quot;</span>, <span class="dt">y=</span><span class="st">&quot;電影數量比率&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.background =</span> <span class="kw">element_blank</span>(),
        <span class="dt">axis.line=</span><span class="kw">element_line</span>(<span class="dt">color=</span><span class="st">&quot;grey&quot;</span>),
        <span class="dt">panel.grid.major.y =</span> <span class="kw">element_line</span>(<span class="dt">color=</span><span class="st">&quot;grey90&quot;</span>))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<hr />
<p>捨棄<code>vote_count</code>和<code>vote_average</code>兩個variables</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies &lt;-<span class="st"> </span>movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>vote_count, <span class="op">-</span>vote_average)</code></pre></div>
<hr />
<p><strong>修改日期資料類型的variables成factor資料類型，然後轉換成one-hot encoding的形式</strong></p>
<p>說明：</p>
<ol style="list-style-type: decimal">
<li><p>因為輸入分類的variables最好是numeric，而且資料的分布比較平均比較好。因此先將日期資料型態改成factor資料型態，再轉變成one-hot encoding的形式。</p></li>
<li><p>one-hot encoding適用於名目或順序尺度的variables。對於某一個名目或順序尺度的variables，如果它有m個可能值，那麼經過one-hot encoding碼後，就變成了m個二元variables(0或1)。每一個二元variable表示原先的variable的一種可能值。例如，某一個variable(稱為light)的可能值為“red”、“yellow”和“green”，將light經過one-hot encoding後，將會產生3個二元variables(red、yellow和green)。如果某一個observation在light上的值是“red”，經過one-hot encoding後，這個observation在red上的值為1，yellow和green則都是0。</p></li>
</ol>
<p>分析<code>release_date</code>，因為其資料型態是<code>Date</code>，所以載入日期時間處理套件</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(lubridate)</code></pre></div>
<p>觀察<code>release_date</code>的分布情形</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(movies<span class="op">$</span>release_date)</code></pre></div>
<pre><code>##         Min.      1st Qu.       Median         Mean      3rd Qu. 
## &quot;1927-01-10&quot; &quot;1999-07-14&quot; &quot;2006-03-06&quot; &quot;2003-05-31&quot; &quot;2011-05-14&quot; 
##         Max. 
## &quot;2016-09-09&quot;</code></pre>
<p>從1927年到2016年，最早期的電影數較少</p>
<p>查看每年的上映電影數</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">release_year=</span><span class="kw">year</span>(release_date)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(release_year) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">count=</span><span class="kw">n</span>()) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>release_year, <span class="dt">y=</span>count)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">limits=</span><span class="kw">c</span>(<span class="dv">1910</span>, <span class="dv">2020</span>), <span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">1910</span>, <span class="dv">2020</span>, <span class="dv">10</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;放映年份&quot;</span>, <span class="dt">y=</span><span class="st">&quot;電影數量&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.background =</span> <span class="kw">element_blank</span>(),
        <span class="dt">panel.grid.major.y =</span> <span class="kw">element_line</span>(<span class="dt">color=</span><span class="st">&quot;grey70&quot;</span>),
        <span class="dt">axis.line =</span> <span class="kw">element_line</span>(<span class="dt">color=</span><span class="st">&quot;grey&quot;</span>))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>以放映年份取代放映日期，並分為1990年前、1991-2000年、2001-2010年與2011年後等四個區間，便於之後的分析</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies &lt;-<span class="st"> </span>movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">release_year=</span><span class="kw">year</span>(release_date)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">release_year=</span><span class="kw">cut</span>(release_year, <span class="dt">breaks=</span><span class="kw">c</span>(<span class="dv">1900</span>, <span class="dv">1990</span>, <span class="dv">2000</span>, <span class="dv">2010</span>, <span class="dv">2020</span>), <span class="dt">labels=</span><span class="kw">c</span>(<span class="st">&quot;before1990&quot;</span>, <span class="st">&quot;between1991_2000&quot;</span>, <span class="st">&quot;between2001_2010&quot;</span>, <span class="st">&quot;after2011&quot;</span>)))</code></pre></div>
<p>檢視各類別內的資料數量</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(release_year) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">count=</span><span class="kw">n</span>()) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ratio=</span>count<span class="op">/</span><span class="kw">sum</span>(count)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>(<span class="kw">aes</span>(<span class="dt">x=</span>release_year, <span class="dt">y=</span>ratio)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;出品年代&quot;</span>, <span class="dt">y=</span><span class="st">&quot;電影數量比率&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.background =</span> <span class="kw">element_blank</span>(),
        <span class="dt">axis.line=</span><span class="kw">element_line</span>(<span class="dt">color=</span><span class="st">&quot;grey&quot;</span>),
        <span class="dt">panel.grid.major.y =</span> <span class="kw">element_line</span>(<span class="dt">color=</span><span class="st">&quot;grey90&quot;</span>),
        <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle=</span><span class="dv">30</span>, <span class="dt">hjust=</span><span class="dv">1</span>))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>將release_year改為one-hot encoding的形式</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies_year &lt;-<span class="st"> </span>movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(id, release_year) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">value=</span><span class="dv">1</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">spread</span>(<span class="dt">key=</span>release_year, <span class="dt">value=</span>value, <span class="dt">fill=</span><span class="dv">0</span>)</code></pre></div>
<p>合併兩個data frame，捨棄<code>release_date</code>和<code>release_year</code>兩個variables</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies &lt;-<span class="st"> </span>movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">left_join</span>(movies_year) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>release_date, <span class="op">-</span>release_year)</code></pre></div>
<pre><code>## Joining, by = &quot;id&quot;</code></pre>
<p>移除<code>movies_year</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">remove</span>(movies_year)</code></pre></div>
<hr />
<p><strong>處理簡單字串類型的variables</strong></p>
<p>簡單字串資料類型與複雜資料的差別是前者的資料格式較單純，簡單字串資料類型只有一個variable：<code>original_language</code>。</p>
<p>分析<code>original_language</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(original_language) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">count=</span><span class="kw">n</span>()) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">proportion=</span>count<span class="op">/</span><span class="kw">sum</span>(count)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(proportion))</code></pre></div>
<pre><code>## # A tibble: 24 x 3
##    original_language count proportion
##    &lt;chr&gt;             &lt;int&gt;      &lt;dbl&gt;
##  1 en                 2615    0.966  
##  2 fr                   18    0.00665
##  3 es                   13    0.00480
##  4 ja                   10    0.00370
##  5 de                    8    0.00296
##  6 zh                    8    0.00296
##  7 it                    5    0.00185
##  8 cn                    4    0.00148
##  9 ko                    4    0.00148
## 10 da                    3    0.00111
## # ... with 14 more rows</code></pre>
<p>可以發現雖然<code>original_language</code>中有許多可能的值，也就是收錄許多語言的電影，但絕大部分是英語片(96.64%)，因此捨棄這個variable</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies &lt;-<span class="st"> </span>movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>original_language)</code></pre></div>
<p>分析<code>production_companies</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies<span class="op">$</span>pc_data &lt;-<span class="st"> </span><span class="kw">sapply</span>(movies<span class="op">$</span>production_companies, valueExtract)</code></pre></div>
<p>將電影的每一個<code>production_companies</code>展開</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies_pc &lt;-<span class="st"> </span>movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(id, pc_data) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pc_data=</span><span class="kw">strsplit</span>(pc_data, <span class="dt">split=</span><span class="st">&quot;%&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">unnest</span>(pc_data) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">value=</span><span class="dv">1</span>)</code></pre></div>
<p>統計電影製作公司與他們製作的電影數 (按電影數排名)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">production_companies &lt;-<span class="st"> </span>movies_pc <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(pc_data) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">count=</span><span class="kw">n</span>()) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(count))</code></pre></div>
<p>製作電影數前100的電影製作公司</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">top100pc &lt;-<span class="st"> </span>production_companies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">pull</span>(pc_data)</code></pre></div>
<p>電影的製作公司包含幾家前100製作公司</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies_pc &lt;-<span class="st"> </span>movies_pc <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">value=</span><span class="kw">ifelse</span>(pc_data <span class="op">%in%</span><span class="st"> </span>top100pc, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(id) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">top_pc_number=</span><span class="kw">sum</span>(value))</code></pre></div>
<p>將電影的製作公司包含前100製作公司的數量與movies合併，捨棄production_companies和pc_data兩個variables，並且將top_pc_number的<code>NA</code>值改為0。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies &lt;-<span class="st"> </span>movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">left_join</span>(movies_pc) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>production_companies, <span class="op">-</span>pc_data) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">top_pc_number=</span><span class="kw">ifelse</span>(<span class="kw">is.na</span>(top_pc_number), <span class="dv">0</span>, top_pc_number))</code></pre></div>
<pre><code>## Joining, by = &quot;id&quot;</code></pre>
<p>繪製電影的知名製作公司數量分布情形</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">top_pc_number=</span><span class="kw">factor</span>(top_pc_number)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(top_pc_number) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">count=</span><span class="kw">n</span>()) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ratio=</span>count<span class="op">/</span><span class="kw">sum</span>(count)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>(<span class="kw">aes</span>(<span class="dt">x=</span>top_pc_number, <span class="dt">y=</span>ratio)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;包含知名製作公司數&quot;</span>, <span class="dt">y=</span><span class="st">&quot;電影數量比率&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.background =</span> <span class="kw">element_blank</span>(),
        <span class="dt">panel.grid.major.y =</span> <span class="kw">element_line</span>(<span class="dt">color=</span><span class="st">&quot;grey90&quot;</span>),
        <span class="dt">axis.line =</span>  <span class="kw">element_line</span>(<span class="dt">color=</span><span class="st">&quot;grey&quot;</span>))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-47-1.png" width="672" /></p>
<p>移除<code>movies_pc</code>、<code>production_companies</code>和<code>top100pc</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">remove</span>(movies_pc)
<span class="kw">remove</span>(production_companies)
<span class="kw">remove</span>(top100pc)</code></pre></div>
<hr />
<p>在進行資料探勘前，最後再檢視一次movies</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(movies)</code></pre></div>
<pre><code>##      budget                id           popularity     
##  Min.   :    10000   Min.   :     5   Min.   :  1.552  
##  1st Qu.: 14000000   1st Qu.:  2988   1st Qu.: 14.982  
##  Median : 30000000   Median : 10581   Median : 24.910  
##  Mean   : 45745024   Mean   : 46166   Mean   : 33.773  
##  3rd Qu.: 60000000   3rd Qu.: 49025   3rd Qu.: 41.502  
##  Max.   :380000000   Max.   :417859   Max.   :875.581  
##     revenue             runtime        vote_average_p   before1990    
##  Min.   :2.200e+04   Min.   : 63.0   (0,5.5]  : 423   Min.   :0.0000  
##  1st Qu.:3.004e+07   1st Qu.: 97.0   (5.5,6.5]:1131   1st Qu.:0.0000  
##  Median :7.582e+07   Median :107.0   (6.5,7.5]: 952   Median :0.0000  
##  Mean   :1.423e+08   Mean   :111.2   (7.5,10] : 200   Mean   :0.1171  
##  3rd Qu.:1.701e+08   3rd Qu.:122.0                    3rd Qu.:0.0000  
##  Max.   :2.788e+09   Max.   :248.0                    Max.   :1.0000  
##  between1991_2000 between2001_2010   after2011         g_Action     
##  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  
##  Median :0.0000   Median :0.0000   Median :0.0000   Median :0.0000  
##  Mean   :0.1807   Mean   :0.4324   Mean   :0.2698   Mean   :0.3012  
##  3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  
##  Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  
##   g_Adventure      g_Animation         g_Comedy         g_Crime      
##  Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000  
##  Median :0.0000   Median :0.00000   Median :0.0000   Median :0.0000  
##  Mean   :0.2251   Mean   :0.06319   Mean   :0.3359   Mean   :0.1704  
##  3rd Qu.:0.0000   3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:0.0000  
##  Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.0000  
##  g_Documentary         g_Drama          g_Family        g_Fantasy     
##  Min.   :0.000000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:0.000000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  
##  Median :0.000000   Median :0.0000   Median :0.0000   Median :0.0000  
##  Mean   :0.004804   Mean   :0.4202   Mean   :0.1186   Mean   :0.1183  
##  3rd Qu.:0.000000   3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:0.0000  
##  Max.   :1.000000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  
##    g_History          g_Horror         g_Music          g_Mystery      
##  Min.   :0.00000   Min.   :0.0000   Min.   :0.00000   Min.   :0.00000  
##  1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.00000  
##  Median :0.00000   Median :0.0000   Median :0.00000   Median :0.00000  
##  Mean   :0.04028   Mean   :0.1153   Mean   :0.02772   Mean   :0.08832  
##  3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.00000   3rd Qu.:0.00000  
##  Max.   :1.00000   Max.   :1.0000   Max.   :1.00000   Max.   :1.00000  
##    g_Romance     g_Science_Fiction   g_Thriller         g_War        
##  Min.   :0.000   Min.   :0.0000    Min.   :0.0000   Min.   :0.00000  
##  1st Qu.:0.000   1st Qu.:0.0000    1st Qu.:0.0000   1st Qu.:0.00000  
##  Median :0.000   Median :0.0000    Median :0.0000   Median :0.00000  
##  Mean   :0.163   Mean   :0.1467    Mean   :0.3123   Mean   :0.03437  
##  3rd Qu.:0.000   3rd Qu.:0.0000    3rd Qu.:1.0000   3rd Qu.:0.00000  
##  Max.   :1.000   Max.   :1.0000    Max.   :1.0000   Max.   :1.00000  
##    g_Western       top_pc_number  
##  Min.   :0.00000   Min.   :0.000  
##  1st Qu.:0.00000   1st Qu.:1.000  
##  Median :0.00000   Median :1.000  
##  Mean   :0.01441   Mean   :1.371  
##  3rd Qu.:0.00000   3rd Qu.:2.000  
##  Max.   :1.00000   Max.   :8.000</code></pre>
<p>捨棄variable <code>id</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies &lt;-<span class="st"> </span>movies <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>id)</code></pre></div>
<p>除了<code>vote_average_p</code>為目標變數外，其餘的變數都為預測變數。</p>
</div>
<div id="section-8.3.2" class="section level3">
<h3><span class="header-section-number">8.3.2</span> 轉換資料為有效描述和預測的特徵</h3>
<p>載入套件</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)</code></pre></div>
<p><strong>建立訓練資料與測試資料</strong></p>
<p>將TMDB電影資料分為訓練集與測試集，訓練資料用來訓練各種分類器，測試資料比較各種分類器的成效。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generate random seed</span>
sd &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">second</span>(<span class="kw">Sys.time</span>())<span class="op">*</span><span class="dv">100</span>)

<span class="kw">set.seed</span>(sd)

<span class="co"># Step 1: Get row numbers for the training data</span>
trainRowNumbers &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(movies<span class="op">$</span>vote_average_p, <span class="dt">p=</span><span class="fl">0.8</span>, <span class="dt">list=</span><span class="ot">FALSE</span>)

<span class="co"># Step 2: Create the training  dataset</span>
train_set &lt;-<span class="st"> </span>movies[trainRowNumbers,]

<span class="co"># Step 3: Create the test dataset</span>
test_set &lt;-<span class="st"> </span>movies[<span class="op">-</span>trainRowNumbers,]</code></pre></div>
<p>調整每個variable的值，前四個variables(budget, popularity, revenue, run_time)根據平均數和標準差進行調整，最後一個variable(top_pc_number)調整為0與1之間</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 以訓練資料集，產生調整參數 (平均數和標準差)</span>
preprocessParams_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">preProcess</span>(train_set[,<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>], <span class="dt">method=</span><span class="kw">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>))
<span class="co"># 調整訓練資料集</span>
train_set[,<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>] &lt;-<span class="st"> </span><span class="kw">predict</span>(preprocessParams_<span class="dv">1</span>, train_set[,<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>])
<span class="co"># 調整測試資料集</span>
test_set[,<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>] &lt;-<span class="st"> </span><span class="kw">predict</span>(preprocessParams_<span class="dv">1</span>, test_set[,<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>])

<span class="co"># 以訓練資料集，產生調整參數 (range:全距，調整為0~1之間的數值)</span>
preprocessParams_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">preProcess</span>(train_set[,<span class="kw">ncol</span>(train_set)], <span class="dt">method=</span><span class="kw">c</span>(<span class="st">&quot;range&quot;</span>))
<span class="co"># 調整訓練資料集</span>
train_set[,<span class="kw">ncol</span>(train_set)] &lt;-<span class="st"> </span><span class="kw">predict</span>(preprocessParams_<span class="dv">2</span>, train_set[,<span class="kw">ncol</span>(train_set)])
<span class="co"># 調整測試資料集</span>
test_set[,<span class="kw">ncol</span>(train_set)] &lt;-<span class="st"> </span><span class="kw">predict</span>(preprocessParams_<span class="dv">2</span>, test_set[,<span class="kw">ncol</span>(train_set)])</code></pre></div>
<p>移除調整參數</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">remove</span>(preprocessParams_<span class="dv">1</span>)
<span class="kw">remove</span>(preprocessParams_<span class="dv">2</span>)</code></pre></div>
<p>移除random seed和訓練集編號</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">remove</span>(sd)
<span class="kw">remove</span>(trainRowNumbers)</code></pre></div>
</div>
<div id="data-frame" class="section level3">
<h3><span class="header-section-number">8.3.3</span> 建立一個data frame用來比較各種分類演算法</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">classifier_comp &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">method=</span><span class="kw">character</span>(<span class="dv">0</span>),
                              <span class="dt">result=</span><span class="kw">double</span>(<span class="dv">0</span>))</code></pre></div>
</div>
</div>
<div id="k-nearest-neightbors" class="section level2">
<h2><span class="header-section-number">8.4</span> 進行K-Nearest Neightbors分類</h2>
<p>K-Nearest Neightbors分類演算法(以下簡稱KNN)，是最直覺的分類演算法。有別於其他監督式機器學習的分類演算法，KNN不需要先利用已經知道類別的資料訓練預測模型，其主要的概念是將要預測的資料與已經知道類別的資料進行比對，找出最相似的K個候選資料(因此稱為K-Nearest Neighbors)，然後對這K個資料統計每個類別的數量，以多數決的方式決定要預測的資料類別。</p>
<p>KNN雖然概念簡單，但還有不錯的結果。因此，常常用來作為其他分類演算法的比較基準。</p>
<p>FNN套件提供KNN分類演算法。安裝後，載入套件</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(FNN)</code></pre></div>
<p>首先找出在訓練資料集中最佳的K值，也就是以多少個候選資料來預測會有較大的準確度。此處以<strong>交互驗證(cross validation, cv)</strong>的方式，找出K為x時，KNN的準確度，然後選取準確度最大的x，做為K。cv是將資料分成多個部分，每一次取出一個部分當做測試資料，以其他部分作為訓練資料，建立預測模型，預測測試資料的結果，估算這個模型的準確度。然後，再取出未曾測試的另一部份資料做為測試資料，以其他部分做為訓練資料，估算準確度。反覆多次，最後將所有獲得的準確度進行平均，做為準確度的估計值。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_k &lt;-<span class="st"> </span><span class="cf">function</span> (x) {
  train_res &lt;-<span class="st"> </span><span class="kw">knn.cv</span>(<span class="kw">subset</span>(train_set, <span class="dt">select=</span><span class="op">-</span>vote_average_p),
                      <span class="dt">cl=</span>train_set<span class="op">$</span>vote_average_p, <span class="dt">k =</span> x)
  acc &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(train_res, train_set<span class="op">$</span>vote_average_p)
  <span class="kw">return</span>(acc<span class="op">$</span>overall[<span class="dv">1</span>])
}</code></pre></div>
<p>從K=1到20分別測試，找出最大準確度的K值。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">accu &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, test_k)</code></pre></div>
<p>計算測試資料集的準確度</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knn_res &lt;-<span class="st"> </span><span class="kw">knn</span>(<span class="kw">subset</span>(train_set, <span class="dt">select=</span><span class="op">-</span>vote_average_p),
               <span class="kw">subset</span>(test_set, <span class="dt">select=</span><span class="op">-</span>vote_average_p),
               <span class="dt">cl=</span>train_set<span class="op">$</span>vote_average_p, <span class="dt">k=</span><span class="kw">which.max</span>(accu))
acc &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(knn_res, test_set<span class="op">$</span>vote_average_p)<span class="op">$</span>overall[<span class="dv">1</span>]

classifier_comp &lt;-<span class="st"> </span>classifier_comp <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_row</span>(<span class="dt">method=</span><span class="st">&quot;KNN&quot;</span>, <span class="dt">result=</span><span class="kw">round</span>(acc<span class="op">*</span><span class="dv">100</span>, <span class="dv">2</span>))</code></pre></div>
<p>移除KNN計算時的暫存變數</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">remove</span>(accu)
<span class="kw">remove</span>(knn_res)</code></pre></div>
</div>
<div id="naive-bayes" class="section level2">
<h2><span class="header-section-number">8.5</span> 進行Naive Bayes演算法分類</h2>
<p>Naive Bayes分類演算法(簡稱NB)是利用Bayes Theorem(貝氏定理)，根據資料特徵計算該資料屬於各類別的機率，以機率最大者做為預測之結果。在這個方法中，首先以訓練資料集建立預測模型(也就是各特徵對於分類的重要性)，然後針對測試資料集的每一筆資料，根據其特徵進行預測。這個方法相當依賴資料特徵的好壞。</p>
<p>安裝NB分類法的套件<code>naivebayes</code>之後，載入該套件</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(naivebayes)</code></pre></div>
<p>因為資料特徵中有許多重覆的或是不重要的資訊，因此利用利用caret套件的pca (principal component analysis)，先將原先的資料特徵轉換成為比較小維度的特徵</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">preprocessParams &lt;-<span class="st"> </span>train_set <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>vote_average_p) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as.matrix</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">preProcess</span>(<span class="dt">method =</span> <span class="st">&quot;pca&quot;</span>, <span class="dt">thresh =</span> <span class="fl">0.8</span>)</code></pre></div>
<p>調整訓練資料集的資料特徵</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 調整訓練資料集</span>
train_fea &lt;-<span class="st"> </span>train_set <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>vote_average_p) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as.matrix</span>()

train_set1 &lt;-<span class="st"> </span><span class="kw">predict</span>(preprocessParams, train_fea) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">vote_average_p=</span>train_set<span class="op">$</span>vote_average_p)</code></pre></div>
<p>以訓練資料集訓練預測模型</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">NB_model &lt;-<span class="st"> </span><span class="kw">naive_bayes</span>(vote_average_p <span class="op">~</span><span class="st"> </span>., 
                               <span class="dt">usekernel=</span><span class="ot">TRUE</span>, <span class="dt">data=</span>train_set1)</code></pre></div>
<p>進行測試</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 調整測試資料集</span>
test_fea &lt;-<span class="st"> </span>test_set <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>vote_average_p) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as.matrix</span>()

test_set1 &lt;-<span class="st"> </span><span class="kw">predict</span>(preprocessParams, test_fea) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as.data.frame</span>()

NB_res &lt;-<span class="st"> </span><span class="kw">predict</span>(NB_model, <span class="dt">newdata=</span>test_set1, <span class="dt">type=</span><span class="st">&quot;class&quot;</span>)

acc &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(NB_res, test_set<span class="op">$</span>vote_average_p)<span class="op">$</span>overall[<span class="dv">1</span>]

classifier_comp &lt;-<span class="st"> </span>classifier_comp <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_row</span>(<span class="dt">method=</span><span class="st">&quot;NB&quot;</span>, <span class="dt">result=</span><span class="kw">round</span>(acc<span class="op">*</span><span class="dv">100</span>, <span class="dv">2</span>))</code></pre></div>
<p>移除NB計算時的暫存變數</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">remove</span>(preprocessParams)
<span class="kw">remove</span>(train_fea)
<span class="kw">remove</span>(train_set1)
<span class="kw">remove</span>(NB_model)
<span class="kw">remove</span>(test_fea)
<span class="kw">remove</span>(test_set1)
<span class="kw">remove</span>(NB_res)</code></pre></div>
</div>
<div id="section-8.6" class="section level2">
<h2><span class="header-section-number">8.6</span> 進行支持向量機分類</h2>
<p>支持向量機(Support Vector Machine, SVM)試圖從訓練資料中找到一個超平面(hyperplane)，將訓練資料區分成兩個具有最大差異的類別。以下圖為例，可以發現右圖上的超平面具有最好的分類結果，因為該超平面距離兩個類別上所有的資料是最大的情形。用來找到這個超平面的資料點上垂直於超平面的向量便稱為支持向量(Support Vectors)，例如在右圖上以實心表現的資料點。當新資料需要進行分類時，便根據超平面判斷新資料的類別。</p>
<div class="figure">
<img src="image/svm.png" />

</div>
<p>由於SVM原本的應用是針對兩個類別的問題，在將SVM應用到多個類別時，需要採用One-against-One的策略，也就是對每兩個類別分別建立一個SVM模型，所以若是有M個類別的話，便須建立<span class="math inline">\(\frac{M(M-1)}{2}\)</span>個SVM模型。當新資料輸入後，便以這立<span class="math inline">\(\frac{M(M-1)}{2}\)</span>個SVM模型進行預測，以多數決決定預測的類別。</p>
<p>e1071套件中提供SVM分類演算法。先安裝後，再載入該套件。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(e1071)</code></pre></div>
<p>利用訓練資料進行分類模型訓練</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SVM_model &lt;-<span class="st"> </span><span class="kw">svm</span>(vote_average_p <span class="op">~</span><span class="st"> </span>., 
                 <span class="dt">data=</span>train_set)</code></pre></div>
<p>預測測試資料的類別，計算其準確度</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SVM_res &lt;-<span class="st"> </span><span class="kw">predict</span>(SVM_model, <span class="dt">newdata=</span>test_set, <span class="dt">type=</span><span class="st">&quot;class&quot;</span>)

acc &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(SVM_res, test_set<span class="op">$</span>vote_average_p)<span class="op">$</span>overall[<span class="dv">1</span>]

classifier_comp &lt;-<span class="st"> </span>classifier_comp <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_row</span>(<span class="dt">method=</span><span class="st">&quot;SVM&quot;</span>, <span class="dt">result=</span><span class="kw">round</span>(acc<span class="op">*</span><span class="dv">100</span>, <span class="dv">2</span>))</code></pre></div>
<p>移SVM計算時的暫存變數</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">remove</span>(SVM_model)
<span class="kw">remove</span>(SVM_res)</code></pre></div>
</div>
<div id="section-8.7" class="section level2">
<h2><span class="header-section-number">8.7</span> 進行決策樹分類</h2>
<p>機器學習中，決策樹是一種樹型結構的分類方法，在樹型結構的第一層分支上對全體的資料依照某一個條件進行分類，分類後盡量使同一群內的資料具有相同的輸出資訊，也就是提高輸出資訊的純度。然後在接下來的第二層分支，再分別對這兩群資料進行分類，使得分類後的結果純度再提高。反覆進行上述的分類過程，當不能再進行分類或一個單獨的類可以被應用於某一分支時，決策樹的建置就完成了。</p>
<p>預測時便從決策樹的最上層，根據節點上的條件判斷其所屬分支，然後由上而下針對每一個條件進行判斷，選擇分支，一直到最下層的節點為止，此時便以該節點上數量最多的類別做為該資料的預設結果。</p>
<div class="figure">
<img src="image/classification_tree.png" />

</div>
<p>套件<code>rpaprt</code>提供決策樹應用。安裝<code>rpaprt</code>套件後，載入這個套件。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rpart)</code></pre></div>
<p>輸入train_set的資料訓練分類樹</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rpart_model &lt;-<span class="st"> </span><span class="kw">rpart</span>(vote_average_p <span class="op">~</span><span class="st"> </span>.,
                     <span class="dt">data =</span> train_set, <span class="dt">method =</span> <span class="st">&quot;class&quot;</span>,
                     <span class="dt">minsplit=</span><span class="dv">30</span>, <span class="dt">cp=</span><span class="fl">0.00001</span>, <span class="dt">xval=</span><span class="dv">5</span>)</code></pre></div>
<p>顯示訓練的結果</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">printcp</span>(rpart_model)</code></pre></div>
<pre><code>## 
## Classification tree:
## rpart(formula = vote_average_p ~ ., data = train_set, method = &quot;class&quot;, 
##     minsplit = 30, cp = 1e-05, xval = 5)
## 
## Variables actually used in tree construction:
##  [1] after2011         before1990        budget           
##  [4] g_Animation       g_Comedy          g_Drama          
##  [7] g_Family          g_History         g_Horror         
## [10] g_Romance         g_Science_Fiction g_Thriller       
## [13] popularity        revenue           runtime          
## 
## Root node error: 1261/2166 = 0.58218
## 
## n= 2166 
## 
##            CP nsplit rel error  xerror     xstd
## 1  0.11260904      0   1.00000 1.00000 0.018203
## 2  0.02141158      1   0.88739 0.88739 0.018444
## 3  0.01982554      2   0.86598 0.87312 0.018451
## 4  0.01348136      5   0.80650 0.84377 0.018451
## 5  0.01308485      6   0.79302 0.83347 0.018446
## 6  0.01268834      8   0.76685 0.83188 0.018445
## 7  0.01110230      9   0.75416 0.82395 0.018438
## 8  0.00793021     11   0.73196 0.81998 0.018435
## 9  0.00753370     12   0.72403 0.81761 0.018432
## 10 0.00634417     14   0.70896 0.80967 0.018423
## 11 0.00555115     15   0.70262 0.80650 0.018419
## 12 0.00475813     16   0.69707 0.80650 0.018419
## 13 0.00449379     17   0.69231 0.79461 0.018402
## 14 0.00396511     20   0.67883 0.78985 0.018394
## 15 0.00356860     23   0.66614 0.78430 0.018384
## 16 0.00343643     25   0.65900 0.78826 0.018391
## 17 0.00317209     28   0.64869 0.78826 0.018391
## 18 0.00277557     33   0.63283 0.79461 0.018402
## 19 0.00237906     41   0.61063 0.79778 0.018407
## 20 0.00198255     46   0.59715 0.81443 0.018429
## 21 0.00185038     51   0.58604 0.82712 0.018441
## 22 0.00158604     54   0.58049 0.82633 0.018441
## 23 0.00132170     62   0.56780 0.82712 0.018441
## 24 0.00079302     68   0.55987 0.82554 0.018440
## 25 0.00039651     76   0.55353 0.83029 0.018444
## 26 0.00001000     78   0.55274 0.83584 0.018447</code></pre>
<p>訓練完成之後，決策樹如果太大，會有過度擬合(overfitting)的問題，也就是太像訓練資料。對於沒有參與訓練的資料，表現可能不理想。所以分類樹通常會經過裁減(pruning)，選擇預測能力較好的部分，也就是上面xerror最小的CP值。</p>
<p>xerror最小值</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">min</span>(rpart_model<span class="op">$</span>cptable[, <span class="st">&quot;xerror&quot;</span>])</code></pre></div>
<pre><code>## [1] 0.7842982</code></pre>
<p>xerror最小的層級</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">which.min</span>(rpart_model<span class="op">$</span>cptable[, <span class="st">&quot;xerror&quot;</span>])</code></pre></div>
<pre><code>## 15 
## 15</code></pre>
<p>xerror最小的CP值</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rpart_model<span class="op">$</span>cptable[<span class="kw">which.min</span>(rpart_model<span class="op">$</span>cptable[, <span class="st">&quot;xerror&quot;</span>]), <span class="st">&quot;CP&quot;</span>]</code></pre></div>
<pre><code>## [1] 0.003568596</code></pre>
<p>以xerror最小的cp值進行裁減</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pruned.tree &lt;-<span class="st"> </span><span class="kw">prune</span>(rpart_model,
                     <span class="dt">cp =</span> rpart_model<span class="op">$</span>cptable[<span class="kw">which.min</span>(rpart_model<span class="op">$</span>cptable[,<span class="st">&quot;xerror&quot;</span>]),<span class="st">&quot;CP&quot;</span>])</code></pre></div>
<p>以訓練好的分類模型進行測試資料(test_set)分類的成效</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_res &lt;-<span class="st"> </span><span class="kw">predict</span>(pruned.tree, test_set, <span class="dt">type =</span> <span class="st">&quot;class&quot;</span>)

acc &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(test_res, test_set<span class="op">$</span>vote_average_p)<span class="op">$</span>overall[<span class="dv">1</span>]

classifier_comp &lt;-<span class="st"> </span>classifier_comp <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_row</span>(<span class="dt">method=</span><span class="st">&quot;Decision Tree&quot;</span>, <span class="dt">result=</span><span class="kw">round</span>(acc<span class="op">*</span><span class="dv">100</span>, <span class="dv">2</span>))</code></pre></div>
<p>為了觀察決策樹上所使用的分類條件，以下將畫出決策樹各層的條件。請安裝rpart.plot套件，並載入該套件</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rpart.plot)</code></pre></div>
<p>因為產生的決策樹相當龐大，所以將畫出的決策樹輸出為尺寸相當大的png檔，便於觀察。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">png</span>(<span class="st">&quot;rpart_tree.png&quot;</span>, <span class="dt">width=</span><span class="dv">2048</span>, <span class="dt">height=</span><span class="dv">1536</span>)
<span class="kw">rpart.plot</span>(pruned.tree, <span class="dt">box.palette=</span><span class="st">&quot;RdBu&quot;</span>, <span class="dt">shadow.col=</span><span class="st">&quot;gray&quot;</span>, <span class="dt">nn=</span><span class="ot">TRUE</span>)
<span class="kw">dev.off</span>()</code></pre></div>
<pre><code>## png 
##   2</code></pre>
<p>移決策樹計算時的暫存變數</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">remove</span>(rpart_model)
<span class="kw">remove</span>(test_res)
<span class="kw">remove</span>(pruned.tree)</code></pre></div>
</div>
<div id="section-8.8" class="section level2">
<h2><span class="header-section-number">8.8</span> 進行隨機森林分類</h2>
<p>隨機森林(random forest)是一個集成式學習(ensemble learning)的分類方法，也就是是將多個分類結果整合起來的方法。隨機森林的得名來自於它是由多個決策樹的分類結果整合起來的方法，並且每一個決策樹的訓練資料集是從原本的訓練資料集<strong>隨機</strong>選取若干observations和variables進行訓練。進行預測時，將輸入的資料分別輸入所有的決策樹，產生每一個決策樹的預測結果，然後以多數決的方式，選取最有可能的類別。</p>
<p>載入隨機森林套件</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(randomForest)</code></pre></div>
<p>利用訓練資料進行分類模型訓練</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rf_model &lt;-<span class="st"> </span><span class="kw">randomForest</span>(vote_average_p <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> train_set)</code></pre></div>
<p>查看每個variable在運用隨機森林進行分類的重要性</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">importance &lt;-<span class="st"> </span><span class="kw">importance</span>(rf_model)
<span class="kw">data.frame</span>(<span class="dt">variable=</span><span class="kw">dimnames</span>(importance)[[<span class="dv">1</span>]],
           <span class="dt">MeanDecreaseGini=</span>importance,
           <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(MeanDecreaseGini)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">reorder</span>(variable, MeanDecreaseGini), <span class="dt">y=</span>MeanDecreaseGini)) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-85-1.png" width="672" /></p>
<p>預測測試資料的類別，計算其準確度</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rf_res &lt;-<span class="st"> </span><span class="kw">predict</span>(rf_model, test_set)

acc &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(rf_res, test_set<span class="op">$</span>vote_average_p)<span class="op">$</span>overall[<span class="dv">1</span>]

classifier_comp &lt;-<span class="st"> </span>classifier_comp <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_row</span>(<span class="dt">method=</span><span class="st">&quot;RF&quot;</span>, <span class="dt">result=</span><span class="kw">round</span>(acc<span class="op">*</span><span class="dv">100</span>, <span class="dv">2</span>))</code></pre></div>
<p>移隨機森林計算時的暫存變數</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">remove</span>(rf_model)
<span class="kw">remove</span>(rf_res)
<span class="kw">remove</span>(importance)</code></pre></div>
</div>
<div id="section-8.9" class="section level2">
<h2><span class="header-section-number">8.9</span> 進行梯度提升機分類</h2>
<p>梯度提升機(Gradient Boosting Machine)是另一種集成式的機器學習技術，透過多個弱預測模型(例如決策樹)的集成來產生。其概念為在訓練新的預測模型時，可從先前模型錯誤分類的資料來增強，也就是給予錯誤分類的資料更大的權重，以訓練新的預測模型。然後將所有的分類模型以它們的預測精準度加權，構建集成模型。理論上，可以應用各種分類演算法做為梯度提升機的基礎分類法，一般使用決策樹做為基礎模型，此時稱為梯度提升樹（GBT或GBDT）。</p>
<p>載入梯度提升樹套件</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(gbm)</code></pre></div>
<p>利用訓練資料進行分類模型訓練</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gbm_model &lt;-<span class="st"> </span><span class="kw">gbm</span>(vote_average_p <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> train_set,
                 <span class="dt">distribution=</span><span class="st">&quot;multinomial&quot;</span>, <span class="dt">n.trees =</span> <span class="dv">1000</span>,
                 <span class="dt">cv.folds =</span> <span class="dv">10</span>)</code></pre></div>
<p>最佳的決策樹數量</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">best_iter &lt;-<span class="st"> </span><span class="kw">gbm.perf</span>(gbm_model, <span class="dt">method=</span><span class="st">&quot;cv&quot;</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-90-1.png" width="672" /></p>
<p>預測測試資料的類別，計算其準確度</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gbm_res &lt;-<span class="st"> </span><span class="kw">predict</span>(gbm_model, test_set, <span class="dt">n.trees=</span>best_iter)

gbm_res_labels &lt;-<span class="st"> </span><span class="kw">as.factor</span>(<span class="kw">colnames</span>(gbm_res)[<span class="kw">apply</span>(gbm_res, <span class="dv">1</span>, which.max)])

acc &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(gbm_res_labels, test_set<span class="op">$</span>vote_average_p)<span class="op">$</span>overall[<span class="dv">1</span>]

classifier_comp &lt;-<span class="st"> </span>classifier_comp <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_row</span>(<span class="dt">method=</span><span class="st">&quot;GBM&quot;</span>, <span class="dt">result=</span><span class="kw">round</span>(acc<span class="op">*</span><span class="dv">100</span>, <span class="dv">2</span>))</code></pre></div>
<p>移隨機森林計算時的暫存變數</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">remove</span>(gbm_model)
<span class="kw">remove</span>(gbm_res)
<span class="kw">remove</span>(gbm_res_labels)
<span class="kw">remove</span>(best_iter)
<span class="kw">remove</span>(acc)</code></pre></div>
</div>
<div id="section-8.10" class="section level2">
<h2><span class="header-section-number">8.10</span> 比較各分類器的結果</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">classifier_comp <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">reorder</span>(method, result), <span class="dt">y=</span>result, <span class="dt">fill=</span>method)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_brewer</span>(<span class="dt">palette=</span><span class="st">&quot;Dark2&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks=</span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">70</span>, <span class="dv">10</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;分類演算法&quot;</span>, <span class="dt">y=</span><span class="st">&quot;測試準確率 (%)&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.background =</span> <span class="kw">element_blank</span>(),
        <span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>,
        <span class="dt">axis.line =</span> <span class="kw">element_line</span>(<span class="dt">colour=</span><span class="st">&quot;grey50&quot;</span>),
        <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle=</span><span class="dv">60</span>, <span class="dt">hjust=</span><span class="dv">1</span>))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-93-1.png" width="672" /></p>
</div>
<div id="-6" class="section level2 unnumbered">
<h2>小結</h2>
<ul>
<li><p>本節探討各種分類演算法。分類演算法是根據已知分類結果的資料特徵訓練一個預測模型，用來預測其它資料的分類結果。</p></li>
<li><p>為了達到上述目的，研究人員發展出許多集群分析演算法，例如：本次課程中使用的K Nearest Neighbors、Naive Bayes、Support Vector Machine、Decision Tree、Random Forest和Gradient Boosting Machine等分類演算法以及其它分類演算法，如著名的Neural Network(神經網絡)。不同的分類演算法適合應用在不同的問題，同學可以熟悉各種分類演算法，以便應用在不同的問題上。</p></li>
<li><p>和上次課程的分類演算法類似，影響分類結果的因素，除了採用的演算法之外，還包括資料的特徵。本次課程中以one-hot encoding, z-score normalization, 以及 min-max scaling三種方法將資料的各種特徵對應到[0, 1]之間的數值，以便彼此的誤差不會相差過大。</p></li>
<li><p>因為訓練資料集與測試資料集為隨機指派，所以每次產生的結果可能會有少部分差異，但大體的趨勢是可以觀察到的。同學可以多試著執行幾次看看會有什麼不同，也可以試著想想，利用k次交叉驗證(k-fold cross validation)獲得較精確的結果。</p></li>
</ul>
</div>
<div id="-6" class="section level2 unnumbered">
<h2>延伸思考</h2>
<ul>
<li><p>什麼樣性質的問題適合應用分類？</p></li>
<li><p>對資料分析來說，選取適當的特徵是很關鍵的步驟，什麼樣的資料類型應選用什麼樣的特徵呢？例如，本次課程中以one-hot encoding, z-score normalization, 以及 min-max scaling三種方法將資料的各種特徵對應到[0, 1]之間的數值，為什麼採用這種特徵？是否有其它更適合的特徵？</p></li>
<li><p>除了課程中練習的分類演算法和有關套件之外，還有許多的分類演算法和套件，如何在R語言中找到適合的套件，並且應用這些套件撰寫程式？</p></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="unsupervised-machine-learning.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/08-supervised_ml.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
